{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5399104b-1664-489e-8471-e20ce97cb540",
   "metadata": {},
   "source": [
    "        Part 1: Understanding Weight Ipitializatio \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554e997b-8b02-4739-9799-34a934e537de",
   "metadata": {},
   "source": [
    "Q1. Explain the importance of weight initialization in artificial neural networks. Why is it necessary to initialize \n",
    "the weights carefully.\n",
    "\n",
    "\n",
    "Weight initialization is a crucial aspect of training artificial neural networks (ANNs). It refers to the process of setting the initial values of the weights in the network before training begins. The importance of weight initialization lies in its impact on the convergence, stability, and performance of the neural network during training. Here are some reasons why careful weight initialization is necessary:\n",
    "\n",
    "1. Avoiding Vanishing/Exploding Gradients: During backpropagation, gradients are propagated backward through the network to update the weights. If the weights are initialized too small (vanishing gradients) or too large (exploding gradients), the gradients can become extremely small or large as they are propagated backward, causing the optimization process to become ineffective or unstable. Proper weight initialization helps mitigate this issue by ensuring that gradients are neither too small nor too large, facilitating smoother and more stable training.\n",
    "\n",
    "2. Balancing Neuron Activations: Weight initialization affects the initial distribution of activations in the network. If the weights are initialized too small, it can lead to saturated activations (i.e., near the upper or lower bounds of activation functions like sigmoid or tanh), which can slow down learning. On the other hand, if the weights are initialized too large, it can cause the activations to quickly reach saturation, hindering the network's ability to capture meaningful patterns in the data. Careful weight initialization helps ensure that the activations are balanced, allowing the network to learn effectively.\n",
    "\n",
    "3. Improving Convergence Speed: Properly initialized weights can help accelerate the convergence of the optimization algorithm (e.g., gradient descent) by providing a good starting point for the optimization process. Faster convergence means that the network requires fewer iterations to reach a satisfactory solution, reducing the overall training time and computational resources required.\n",
    "\n",
    "4. Facilitating Generalization: Weight initialization can influence the capacity of the network to generalize well to unseen data. By initializing the weights appropriately, the network can start with a configuration that is more likely to capture relevant features and patterns in the data, leading to better generalization performance on new, unseen examples.\n",
    "\n",
    "5. Addressing Symmetry Breaking: In networks with symmetric activation functions (e.g., sigmoid or tanh), initializing all weights to the same value would result in neurons with identical behavior, causing symmetry breaking issues and limiting the expressiveness of the network. Careful weight initialization methods, such as random initialization from a suitable distribution (e.g., Gaussian or uniform), help break this symmetry and promote the diversity of neuron behaviors, enhancing the network's representational power."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6702bd0-44f2-4376-90f2-1a0a00b30502",
   "metadata": {},
   "source": [
    "Q2. Describe the challenges associated with improper weight initialization. How do these issues affect model \n",
    "training and convergence.?\n",
    "\n",
    "Improper weight initialization can significantly impact the training and convergence of neural network models. Let’s delve into the challenges associated with it:\n",
    "\n",
    "\n",
    "1. Vanishing Gradient Problem:\n",
    "\n",
    "When weights are initialized too small (e.g., close to zero), the gradients during backpropagation become tiny as they propagate through each layer. Consequently, the model learns very slowly, and the updates to the weights are minimal.\n",
    "\n",
    "This issue hampers the training process, especially in deep networks, where gradients can vanish exponentially as they flow backward through layers.\n",
    "The result is poor convergence, slow learning, and suboptimal performance.\n",
    "\n",
    "2. Exploding Gradient Problem:\n",
    "\n",
    "Conversely, if weights are initialized too large (e.g., with large random values), the gradients explode during backpropagation.\n",
    "Large gradients lead to unstable training, causing weight updates that overshoot the optimal values.\n",
    "The model may diverge, fail to converge, or exhibit erratic behavior during training.\n",
    "\n",
    "3. Overfitting:\n",
    "\n",
    "Random initialization can lead to overfitting, where the model performs well on the training data but poorly on unseen data.\n",
    "Overfitting occurs when the model learns noise or specific patterns in the training data rather than generalizing well.\n",
    "Proper weight initialization helps mitigate overfitting by providing a better starting point for optimization.\n",
    "\n",
    "4. Non-Reproducibility:\n",
    "\n",
    "If weights are randomly initialized differently in each run, the model’s behavior becomes non-reproducible.\n",
    "Reproducibility is crucial for research, debugging, and comparing different models.\n",
    "Consistent weight initialization ensures reproducibility across experiments.\n",
    "\n",
    "5. Convergence Speed:\n",
    "\n",
    "Proper initialization affects how quickly the model converges to a good solution.\n",
    "Well-initialized weights allow the model to learn efficiently, reducing the number of training iterations needed.\n",
    "Faster convergence saves computational resources and training time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92cf7809-e808-4e12-abfc-fc11160a6976",
   "metadata": {},
   "source": [
    " Q3. Discuss the concept of variance and how it relates to weight initialization. WhE is it crucial to consider the \n",
    "variance of weights during initialization?\n",
    "\n",
    "    Variance and Weight Initialization:\n",
    "\n",
    "Variance measures the spread or dispersion of a set of values. In the context of neural networks, it refers to the variability of weights assigned to connections between neurons.\n",
    "\n",
    "When initializing weights, we want to strike a balance:\n",
    "\n",
    "Too low variance: If weights have very low variance (e.g., all initialized to zero), the network may struggle to learn diverse features. Neurons will behave similarly, leading to slow convergence and limited expressiveness.\n",
    "\n",
    "Too high variance: If weights have very high variance (e.g., large random values), the network becomes unstable. Gradients during training can explode, causing erratic behavior and divergence.\n",
    "\n",
    "Proper variance ensures that weights are initialized in a way that facilitates efficient learning and convergence.\n",
    "\n",
    "Why Consider Variance During Initialization?:\n",
    "\n",
    "Stability and Gradient Flow: Properly initialized weights help stabilize training. When gradients flow backward during backpropagation, balanced variance prevents them from vanishing (too small) or exploding (too large).\n",
    "\n",
    "Faster Convergence: Well-initialized weights allow the model to converge faster toward an optimal solution. Faster convergence saves computational resources and training time.\n",
    "\n",
    "Avoiding Overfitting: Appropriate variance reduces the risk of overfitting. Overfitting occurs when the model learns noise or specific patterns in the training data instead of generalizing well to unseen data.\n",
    "\n",
    "Reproducibility: Consistent variance ensures reproducibility across experiments, making research and debugging easier.\n",
    "\n",
    "Common Weight Initialization Techniques:\n",
    "\n",
    "Zero Initialization: Assigning all weights as zeros is ineffective because neurons learn the same feature during each iteration. It leads to slow convergence.\n",
    "\n",
    "Random Initialization:\n",
    "Assign random values (except zeros) to weights.\n",
    "\n",
    "Two common methods:\n",
    "\n",
    "Random Normal: Initialize weights from a normal distribution.\n",
    "\n",
    "Random Uniform: Initialize weights from a uniform distribution.\n",
    "\n",
    "Xavier (Glorot) Initialization:\n",
    "Calculates weights from a uniform distribution with variance proportional to the number of inputs and outputs for a given neuron.\n",
    "Helps balance gradients and facilitates convergence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a1ee7f4-ceb5-4e9b-abcb-40efbbd1338d",
   "metadata": {},
   "source": [
    "                        Part 2: Weight Ipitializatiop Techpique"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c9d5096-e4de-478b-8cdf-26762b76c50d",
   "metadata": {},
   "source": [
    "Q4.  Explain the concept of zero initialization. Discuss its potential limitations and when it can be appropriate \n",
    "to use.\n",
    "\n",
    "Zero initialization is a weight initialization technique where all the weights in the neural network are initialized to zero. It's one of the simplest methods to initialize weights and is easy to implement. However, while zero initialization has its advantages in certain scenarios, it also comes with significant limitations.\n",
    "\n",
    "Advantages:\n",
    "\n",
    "1. Simplicity: Zero initialization is straightforward to implement since it involves setting all weights to the same value, namely zero.\n",
    "\n",
    "2. Efficiency: Initializing weights to zero requires minimal computational overhead, making it efficient in terms of both memory and processing resources.\n",
    "\n",
    "3. Easy to interpret: With zero initialization, there's a clear starting point for all weights, making it easier to interpret and analyze the behavior of the network during training.\n",
    "\n",
    "Limitations:\n",
    "\n",
    "1. Symmetry Breaking: Perhaps the most critical limitation of zero initialization is that it \n",
    "leads to symmetry breaking issues, particularly in networks with symmetric activation functions such as sigmoid or tanh. When all weights are initialized to zero, each neuron in the network behaves identically, resulting in the same gradients during backpropagation. This symmetry impedes the network's ability to learn diverse representations and limits its capacity to capture complex patterns in the data.\n",
    "\n",
    "2. Vanishing Gradients: Another significant limitation of zero initialization is the potential for vanishing gradients, especially in deeper networks. When gradients become very small or zero, they fail to update the weights effectively, hindering the learning process and causing the network to converge slowly or not at all.\n",
    "\n",
    "3. Reduced Expressiveness: Initializing all weights to zero restricts the network's expressiveness and capacity to represent complex functions. The absence of diversity in initial weights limits the range of functions that the network can learn, potentially leading to suboptimal performance and generalization.\n",
    "\n",
    "When can it be appropriate to use:\n",
    "\n",
    "Despite its limitations, there are certain scenarios where zero initialization may be appropriate or beneficial:\n",
    "\n",
    "1. Sparse Activation: In networks where sparsity is desired, such as autoencoders or sparse coding models, zero initialization can be suitable. By initializing weights to zero, the network may encourage sparsity in activations, where only a subset of neurons is active for a given input, promoting efficient representation of the data.\n",
    "\n",
    "2. Transfer Learning: In transfer learning scenarios where pre-trained weights are fine-tuned on a new task or dataset, zero initialization can serve as a starting point before fine-tuning. It allows the network to initially rely on the pre-trained weights while adapting to the specifics of the new task during fine-tuning.\n",
    "\n",
    "3. Regularization: Zero initialization can be used as a form of regularization, particularly in combination with other regularization techniques such as weight decay or dropout. By starting from a constrained initial state (i.e., all weights set to zero), the network may be less prone to overfitting and better generalize to unseen data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc52f827-8b63-47ce-9cb0-134dd5a092a5",
   "metadata": {},
   "source": [
    "Q6.  Discuss the concept of Xavier/Glorot initialization. Explain how it addresses the challenges of improper \n",
    "weight initialization and the underlying theory behind it.\n",
    "\n",
    "\n",
    "Xavier initialization, also known as Glorot initialization, is a popular weight initialization technique proposed by Xavier Glorot and Yoshua Bengio. It aims to address the challenges associated with improper weight initialization, such as vanishing or exploding gradients, by providing a principled approach to setting the initial values of the weights in a neural network.\n",
    "\n",
    "The key idea behind Xavier initialization is to carefully scale the initial weights to ensure that the variance of the activations remains approximately constant across different layers of the network. This helps in stabilizing the gradients during backpropagation and promotes smoother training dynamics. The initialization is based on the following underlying theory:\n",
    "\n",
    "1. Activation Variance Preservation: In a neural network, the output of each layer is determined by the input data and the weights associated with that layer. The variance of the activations (outputs) of each layer should ideally remain consistent throughout the network to facilitate effective gradient flow during training. If the variance becomes too large or too small, it can lead to vanishing or exploding gradients, respectively, which hinders the convergence of the optimization algorithm.\n",
    "\n",
    "2. Initialization Scale: Xavier initialization aims to set the initial weights in such a way that the scale of the variance of the activations is preserved across layers. This is achieved by scaling the weights based on the number of input and output connections to a neuron.\n",
    "\n",
    "3. Uniform Distribution: Xavier initialization assumes that the activations and gradients are distributed uniformly across the layers of the network. Under this assumption, the scale factor for initializing weights can be derived analytically to ensure that the variance of the activations remains constant.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe7e384-c542-458f-9b7b-7901ed32a8c4",
   "metadata": {},
   "source": [
    "Q7. Explain the concept of He initialization. How does it differ from Xavier initialization, and when is it \n",
    "preferred?\n",
    "\n",
    "He initialization, proposed by Kaiming He et al., is another widely used weight initialization technique, especially in deep neural networks. It addresses some limitations of Xavier initialization, particularly in networks with rectified linear unit (ReLU) activation functions.\n",
    "\n",
    "The key difference between He initialization and Xavier initialization lies in how they scale the initial weights based on the number of input and output connections to a neuron. While Xavier initialization assumes a uniform distribution of activations and gradients, He initialization takes into account the properties of specific activation functions, particularly ReLU.\n",
    "\n",
    "Here's how He initialization differs from Xavier initialization:\n",
    "\n",
    "1. Scale Factor: He initialization scales the initial weights differently compared to Xavier initialization. Instead of dividing by the sum of the number of input and output connections as in Xavier initialization, He initialization only considers the number of input connections to a neuron. This is based on the observation that ReLU units can lead to a reduction in the variance of activations during forward propagation, and therefore require higher initial weights to maintain a stable variance.\n",
    "\n",
    "\n",
    "When is He initialization preferred?\n",
    "\n",
    "He initialization is particularly preferred in networks that use ReLU activation functions or its variants (e.g., leaky ReLU, parametric ReLU) because ReLU units are prone to the problem of \"dying ReLU\" when initialized improperly. Dying ReLU refers to neurons that become inactive (outputting zero) for all inputs during training, effectively \"dying\" and failing to contribute to the learning process. This typically happens when the weights are initialized to very small values, leading to a situation where the ReLU activation function always outputs zero for any input that results in negative values.\n",
    "\n",
    "By initializing weights according to He initialization, the initial scale of weights is adjusted to better suit the properties of ReLU activation functions, helping to alleviate the problem of dying ReLU and promoting more effective training in deep neural networks. Therefore, He initialization is preferred in networks that primarily use ReLU or its variants as activation functions. However, it's worth noting that He initialization may not be as suitable for networks with different activation functions, where Xavier initialization or other initialization strategies may be more appropriate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f97c558b-1072-4979-a0b8-0a99592b626f",
   "metadata": {},
   "source": [
    "                        Part 3: Applyipg Weight Ipitializatioo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c98e83b7-3035-4cd3-a34e-b712e8d41d50",
   "metadata": {},
   "source": [
    "Q8. Implement different weight initialization techniques (zero initialization, random initialization, Xavier \n",
    "initialization, and He initialization) in a neural network using a framework of Eour choice. Train the model \n",
    "on a suitable dataset and compare the performance of the initialized models?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d405adc-4fe2-41b6-a3b3-e18f06ef8426",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /opt/conda/lib/python3.10/site-packages (2.15.0.post1)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.5.4)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (4.4.0)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from tensorflow) (22.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.4.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.1.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (16.0.6)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.60.1)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (23.5.26)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: ml-dtypes~=0.2.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.23.5)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.36.0)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.14.1)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from tensorflow) (65.5.1)\n",
      "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.15.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.7.0)\n",
      "Requirement already satisfied: tensorboard<2.16,>=2.15 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.15.1)\n",
      "Requirement already satisfied: keras<2.16,>=2.15.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.15.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (4.21.11)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow) (0.38.4)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.27.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.28.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.5.2)\n",
      "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.3.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (1.26.13)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.5.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e4e96948-10e6-41be-b59f-7d1cc0aa7f62",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-08 13:07:48.067294: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-02-08 13:07:48.132584: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-02-08 13:07:48.132648: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-02-08 13:07:48.134150: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-02-08 13:07:48.143413: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-02-08 13:07:48.144498: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-02-08 13:07:49.334016: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, initializers\n",
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "# Load the MNIST dataset\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Normalize the pixel values to the range [0, 1]\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f6955540-6181-4cc2-8c0b-0fdc3c106494",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(init_method):\n",
    "    model = models.Sequential([\n",
    "        layers.Flatten(input_shape=(28, 28)),\n",
    "        layers.Dense(128, activation='relu', kernel_initializer=init_method),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6f6f3f12-e008-42b5-a3dc-ef411ae397cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_init = initializers.Zeros()\n",
    "\n",
    "# Random initialization\n",
    "random_init = initializers.RandomNormal(mean=0.0, stddev=0.05, seed=42)\n",
    "\n",
    "# Xavier initialization\n",
    "xavier_init = initializers.GlorotUniform(seed=42)\n",
    "\n",
    "# He initialization\n",
    "he_init = initializers.HeNormal(seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d8da042e-7b27-4416-8db0-2f5c8424c73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_model = create_model(zero_init)\n",
    "zero_history = zero_model.fit(x_train, y_train, epochs=10, validation_data=(x_test, y_test), verbose=0)\n",
    "\n",
    "random_model = create_model(random_init)\n",
    "random_history = random_model.fit(x_train, y_train, epochs=10, validation_data=(x_test, y_test), verbose=0)\n",
    "\n",
    "xavier_model = create_model(xavier_init)\n",
    "xavier_history = xavier_model.fit(x_train, y_train, epochs=10, validation_data=(x_test, y_test), verbose=0)\n",
    "\n",
    "he_model = create_model(he_init)\n",
    "he_history = he_model.fit(x_train, y_train, epochs=10, validation_data=(x_test, y_test), verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f016acd5-8dfc-47bd-902f-16a3b6620f08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "da3521ad-7b08-4dcf-bb70-758fda1b270e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fb194b05-5fa7-4b2b-a93e-d91669156ce3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(zero_history.history['val_accuracy'], label='Zero Initialization')\n",
    "plt.plot(random_history.history['val_accuracy'], label='Random Initialization')\n",
    "plt.plot(xavier_history.history['val_accuracy'], label='Xavier Initialization')\n",
    "plt.plot(he_history.history['val_accuracy'], label='He Initialization')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Comparison of Weight Initialization Methods')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a463360-2cf0-47ad-ab14-65ff0b8466f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7a54e84f-b68f-4a83-9733-fc984b5c00d3",
   "metadata": {},
   "source": [
    "Q9. Discuss the considerations and tradeoffs when choosing the appropriate weight initialization technique \n",
    "for a given neural network architecture and task?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4874bc76-520f-458c-91d7-9f8e7d5b37d3",
   "metadata": {},
   "source": [
    "Choosing the appropriate weight initialization technique for a neural network involves considering various factors and tradeoffs. Here are some key considerations and tradeoffs to keep in mind:\n",
    "\n",
    "1. Activation Function: Different weight initialization techniques may perform differently depending on the activation functions used in the network. For example, He initialization is particularly suitable for networks using rectified linear unit (ReLU) activation functions, while Xavier initialization may be more appropriate for networks with sigmoid or hyperbolic tangent (tanh) activations.\n",
    "\n",
    "2. Network Architecture: The architecture of the neural network, including its depth and width, can influence the choice of weight initialization technique. Deeper networks may benefit from initialization methods that can mitigate the vanishing or exploding gradient problems, such as He initialization. Conversely, shallower networks may not require as sophisticated initialization methods.\n",
    "\n",
    "3. Task Complexity: The complexity of the task the network is intended to solve can also impact the choice of weight initialization technique. For simpler tasks or shallow networks, simpler initialization methods like random initialization or Xavier initialization may suffice. However, for more complex tasks or deeper networks, more advanced initialization techniques like He initialization may be necessary to ensure effective training.\n",
    "\n",
    "4. Computational Resources: Some weight initialization techniques may require more computational resources or memory compared to others. For example, He initialization involves computing the square root of the number of input connections to each neuron, which can be computationally expensive in large networks. Considerations about computational efficiency may influence the choice of weight initialization method, especially in resource-constrained environments.\n",
    "\n",
    "5. Training Stability: Certain weight initialization techniques may lead to more stable training dynamics compared to others. Initialization methods that help stabilize gradients and promote smoother convergence, such as Xavier initialization, may be preferred in situations where training stability is crucial, such as training large networks or dealing with noisy or sparse data.\n",
    "\n",
    "6. Regularization: Weight initialization can also interact with regularization techniques such as dropout, L2 regularization, or batch normalization. Some initialization methods may complement certain regularization techniques, while others may not interact well and lead to suboptimal performance. It's essential to consider the interplay between weight initialization and regularization when designing the network architecture.\n",
    "\n",
    "7. Empirical Performance: Finally, empirical evaluation and experimentation can provide valuable insights into the performance of different weight initialization techniques on a specific task and dataset. Conducting experiments with multiple initialization methods and evaluating their performance on validation data can help identify the most effective initialization strategy for the given task and architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88baf8c4-421a-406e-a196-0de771e0448d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "511082b4-42a1-4fde-aa03-3f17ce887012",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a3939d9-86ce-46cb-98a5-dcd8a5e04e3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "057566b1-1c2e-4890-a5f4-dcea95632c10",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
